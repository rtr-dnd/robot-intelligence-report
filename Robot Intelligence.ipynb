{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "  max_x = np.max(x)\n",
    "  exp_x = np.exp(x - max_x)\n",
    "  return exp_x / np.sum(exp_x)\n",
    "\n",
    "def sigmoid(z):\n",
    "  return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "  return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def act_func(u: float) -> float:\n",
    "  return max(0, u)\n",
    "#   return sigmoid(u)\n",
    "\n",
    "def act_func_prime(z_vec):\n",
    "  return_vec = np.zeros(len(z_vec))\n",
    "  return_vec[z_vec >= 0] = 1\n",
    "  return return_vec\n",
    "#   return_vec = np.zeros(len(z_vec))\n",
    "#   for i in range(0, len(return_vec)):\n",
    "#     return_vec[i] = sigmoid_prime(z_vec[i])\n",
    "#   return return_vec\n",
    "\n",
    "def loss_func(res_vec, target_vec):\n",
    "  return np.sum(np.power(res_vec - target_vec, 2)) / 2\n",
    "\n",
    "def loss_derivative(y_vec, t_vec):\n",
    "  return y_vec - t_vec\n",
    "\n",
    "class perceptron:\n",
    "  # input: size(int), output: 1\n",
    "  def __init__(self, size: int):\n",
    "    self.w_vec = np.random.randn(size)\n",
    "    self.bias = 0\n",
    "\n",
    "  def calc(self, x_vec):\n",
    "    u = np.sum(np.multiply(x_vec, self.w_vec)) + self.bias\n",
    "    return (u, act_func(u))\n",
    "\n",
    "  def train(self, x_vec, d: float, kappa: float):\n",
    "    # d: target value, kappa: learning coeff\n",
    "    self.w_vec -= kappa * (self.calc(x_vec) - d) * x_vec\n",
    "    print('trained')\n",
    "  \n",
    "  def set(self, w_vec, bias):\n",
    "    self.w_vec = w_vec\n",
    "    self.bias = bias\n",
    "\n",
    "class layer:\n",
    "  def __init__(self, prev_node_num: int, percep_num: int):\n",
    "    self.perceptrons = []\n",
    "    for i in range(0, percep_num):\n",
    "      self.perceptrons.append(perceptron(prev_node_num))\n",
    "    self.z_vec = np.zeros(percep_num) # before act_func\n",
    "    self.y_vec = np.zeros(percep_num) # after act_func\n",
    "  \n",
    "  def forward(self, prev_y_vec):\n",
    "    for i in range(0, len(self.perceptrons)):\n",
    "      (this_z, this_y) = self.perceptrons[i].calc(prev_y_vec)\n",
    "      self.z_vec[i] = this_z\n",
    "      self.y_vec[i] = this_y\n",
    "  \n",
    "class input_layer:\n",
    "  def __init__(self, size):\n",
    "    self.y_vec = np.zeros(size)\n",
    "  \n",
    "  def set_y(self, input_vec):\n",
    "    self.y_vec = input_vec\n",
    "\n",
    "def train_network(iteration: int):\n",
    "  cost_avgs = []\n",
    "  for i_iteration in range(0, iteration):\n",
    "    if i_iteration % 10 == 0:\n",
    "      print('iteration ' + str(i_iteration))\n",
    "    cost_avg = 0\n",
    "    y_vec_arr = []\n",
    "    delta = []\n",
    "    for (cur_train_image, cur_train_label) in zip(train_images, train_labels):\n",
    "      #(cur_train_image, cur_train_label) = (train_images[0], train_labels[0])\n",
    "      y_vec_arr.append([])\n",
    "      layers[0].set_y(cur_train_image.flatten())\n",
    "      y_vec_arr[-1].append(layers[0].y_vec)\n",
    "      for i in range(1, len(layers)):\n",
    "        layers[i].forward(layers[i-1].y_vec)\n",
    "        y_vec_arr[-1].append(layers[i].y_vec)\n",
    "        \n",
    "      train_vector = np.zeros(10)\n",
    "      train_vector[cur_train_label] = 1\n",
    "      delta.append([]) # delta[i][j][k]: ith train img, jth layer, kth perceptron(?)\n",
    "      for i in range(0, len(layers)):\n",
    "        delta[-1].append([])\n",
    "      delta[-1][-1] = loss_derivative(layers[-1].y_vec, train_vector) * act_func_prime(layers[-1].z_vec)\n",
    "      cost_avg += loss_func(layers[-1].y_vec, train_vector)\n",
    "\n",
    "      for i in reversed(range(1, len(layers) - 1)):\n",
    "        # print('layer ' + str(i))\n",
    "        # print('perceptrons ' + str(len(layers[i+1].perceptrons)))\n",
    "        # print('w ' + str(len(layers[i+1].perceptrons[0].w_vec)))\n",
    "        # print('delta ' + str(len(delta[-1][i+1])))\n",
    "        # print('z_vec ' + str(len(layers[i].z_vec)))\n",
    "        w_mat = np.zeros((len(layers[i+1].perceptrons), len(layers[i+1].perceptrons[0].w_vec)))\n",
    "        for i_p in range(0, len(layers[i+1].perceptrons)):\n",
    "          # w_delta[i_p] = np.dot(layers[i+1].perceptrons[i_p].w_vec, delta[i+1])\n",
    "          w_mat[i_p] = layers[i+1].perceptrons[i_p].w_vec\n",
    "        w_delta = np.dot(np.transpose(w_mat), delta[-1][i+1])\n",
    "        delta[-1][i] = w_delta * act_func_prime(layers[i].z_vec)\n",
    "\n",
    "    # print('delta ' + str(delta[0][-1]))\n",
    "\n",
    "    for i in range(1, len(layers)):\n",
    "      w_mat = np.zeros((len(layers[i].perceptrons), len(layers[i].perceptrons[0].w_vec)))\n",
    "      bias_vec = np.zeros(len(layers[i].perceptrons))\n",
    "      for i_p in range(0, len(layers[i].perceptrons)):\n",
    "        w_mat[i_p] = layers[i].perceptrons[i_p].w_vec\n",
    "        bias_vec[i_p] = layers[i].perceptrons[i_p].bias\n",
    "      delta_sum = np.zeros(len(delta[0][i]))\n",
    "      delta_a_sum = np.zeros(w_mat.shape)\n",
    "      for i_x in range(0, len(train_images)):\n",
    "        delta_sum += delta[i_x][i]\n",
    "        # print(w_mat.shape)\n",
    "        # print(delta[i_x][i].shape)\n",
    "        # print(y_vec_arr[i_x][i-1].shape)\n",
    "        # print(np.outer(delta[i_x][i], y_vec_arr[i_x][i-1]))\n",
    "        delta_a_sum += np.outer(delta[i_x][i], y_vec_arr[i_x][i-1])\n",
    "      w_new = w_mat - ((kappa / len(train_images)) * delta_a_sum) # prev_perceptron * this_perceptronの行列\n",
    "      # bias_new = bias_vec - kappa / len(train_images) * np.sum(delta, axis=0)\n",
    "      bias_new = bias_vec - kappa / len(train_images) * delta_sum\n",
    "      # print('w before ' + str(w_mat))\n",
    "      # print('delta sum ' + str(delta_a_sum))\n",
    "      # print('w new ' + str(w_new))\n",
    "      # print(bias_new)\n",
    "      for i_p in range(0, len(layers[i].perceptrons)):\n",
    "        layers[i].perceptrons[i_p].set(w_new[i_p], bias_new[i_p])\n",
    "    cost_avg /= len(train_images)\n",
    "    cost_avgs.append(cost_avg)\n",
    "  x_axis = np.arange(iteration)\n",
    "  plt.plot(x_axis, cost_avgs)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def train_network_batch(batch_size: int, batch_time: int):\n",
    "  cost_avgs = []\n",
    "  \n",
    "  for i_batch in range(0, batch_time):\n",
    "    batched_train_images = train_images[i_batch * batch_size : (i_batch + 1) * batch_size]\n",
    "    batched_train_labels = train_labels[i_batch * batch_size : (i_batch + 1) * batch_size]\n",
    "    print('batch num ' + str(i_batch))\n",
    "    cost_avg = 0\n",
    "    y_vec_arr = []\n",
    "    delta = []\n",
    "    for (cur_train_image, cur_train_label) in zip(batched_train_images, batched_train_labels):\n",
    "      #(cur_train_image, cur_train_label) = (train_images[0], train_labels[0])\n",
    "      y_vec_arr.append([])\n",
    "      layers[0].set_y(cur_train_image.flatten())\n",
    "      y_vec_arr[-1].append(layers[0].y_vec)\n",
    "      for i in range(1, len(layers)):\n",
    "        layers[i].forward(layers[i-1].y_vec)\n",
    "        y_vec_arr[-1].append(layers[i].y_vec)\n",
    "        \n",
    "      train_vector = np.zeros(10)\n",
    "      train_vector[cur_train_label] = 1\n",
    "      delta.append([]) # delta[i][j][k]: ith train img, jth layer, kth perceptron(?)\n",
    "      for i in range(0, len(layers)):\n",
    "        delta[-1].append([])\n",
    "      delta[-1][-1] = loss_derivative(layers[-1].y_vec, train_vector) * act_func_prime(layers[-1].z_vec)\n",
    "      cost_avg += loss_func(layers[-1].y_vec, train_vector)\n",
    "\n",
    "      for i in reversed(range(1, len(layers) - 1)):\n",
    "        # print('layer ' + str(i))\n",
    "        # print('perceptrons ' + str(len(layers[i+1].perceptrons)))\n",
    "        # print('w ' + str(len(layers[i+1].perceptrons[0].w_vec)))\n",
    "        # print('delta ' + str(len(delta[-1][i+1])))\n",
    "        # print('z_vec ' + str(len(layers[i].z_vec)))\n",
    "        w_mat = np.zeros((len(layers[i+1].perceptrons), len(layers[i+1].perceptrons[0].w_vec)))\n",
    "        for i_p in range(0, len(layers[i+1].perceptrons)):\n",
    "          # w_delta[i_p] = np.dot(layers[i+1].perceptrons[i_p].w_vec, delta[i+1])\n",
    "          w_mat[i_p] = layers[i+1].perceptrons[i_p].w_vec\n",
    "        w_delta = np.dot(np.transpose(w_mat), delta[-1][i+1])\n",
    "        delta[-1][i] = w_delta * act_func_prime(layers[i].z_vec)\n",
    "\n",
    "    # print('delta ' + str(delta[0][-1]))\n",
    "\n",
    "    for i in range(1, len(layers)):\n",
    "      w_mat = np.zeros((len(layers[i].perceptrons), len(layers[i].perceptrons[0].w_vec)))\n",
    "      bias_vec = np.zeros(len(layers[i].perceptrons))\n",
    "      for i_p in range(0, len(layers[i].perceptrons)):\n",
    "        w_mat[i_p] = layers[i].perceptrons[i_p].w_vec\n",
    "        bias_vec[i_p] = layers[i].perceptrons[i_p].bias\n",
    "      delta_sum = np.zeros(len(delta[0][i]))\n",
    "      delta_a_sum = np.zeros(w_mat.shape)\n",
    "      for i_x in range(0, len(batched_train_images)):\n",
    "        delta_sum += delta[i_x][i]\n",
    "        # print(w_mat.shape)\n",
    "        # print(delta[i_x][i].shape)\n",
    "        # print(y_vec_arr[i_x][i-1].shape)\n",
    "        # print(np.outer(delta[i_x][i], y_vec_arr[i_x][i-1]))\n",
    "        delta_a_sum += np.outer(delta[i_x][i], y_vec_arr[i_x][i-1])\n",
    "      w_new = w_mat - ((kappa / len(batched_train_images)) * delta_a_sum) # prev_perceptron * this_perceptronの行列\n",
    "      # bias_new = bias_vec - kappa / len(train_images) * np.sum(delta, axis=0)\n",
    "      bias_new = bias_vec - kappa / len(batched_train_images) * delta_sum\n",
    "      # print('w before ' + str(w_mat))\n",
    "      # print('delta sum ' + str(delta_a_sum))\n",
    "      # print('w new ' + str(w_new))\n",
    "      # print(bias_new)\n",
    "      for i_p in range(0, len(layers[i].perceptrons)):\n",
    "        layers[i].perceptrons[i_p].set(w_new[i_p], bias_new[i_p])\n",
    "    cost_avg /= len(batched_train_images)\n",
    "    cost_avgs.append(cost_avg)\n",
    "  x_axis = np.arange(batch_time)\n",
    "  plt.plot(x_axis, cost_avgs)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist loaded\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "test_images = np.array(np.float32(test_images)) / 255\n",
    "train_images = np.array(np.float32(train_images)) / 255\n",
    "train_images = train_images\n",
    "train_labels = train_labels\n",
    "print('mnist loaded')\n",
    "\n",
    "network_size = [len(test_images[0].flatten()), 64, 10]\n",
    "kappa = 0.001\n",
    "\n",
    "layers = []\n",
    "layers.append(input_layer(len(test_images[0].flatten())))\n",
    "for i in range(1, len(network_size)):\n",
    "  layers.append(layer(network_size[i-1], network_size[i]))\n",
    "\n",
    "# train_images = train_images[0:10]\n",
    "# train_labels = train_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch num 0\n",
      "batch num 1\n",
      "batch num 2\n",
      "batch num 3\n",
      "batch num 4\n",
      "batch num 5\n",
      "batch num 6\n",
      "batch num 7\n",
      "batch num 8\n",
      "batch num 9\n",
      "batch num 10\n",
      "batch num 11\n",
      "batch num 12\n",
      "batch num 13\n",
      "batch num 14\n",
      "batch num 15\n",
      "batch num 16\n",
      "batch num 17\n",
      "batch num 18\n",
      "batch num 19\n",
      "batch num 20\n",
      "batch num 21\n",
      "batch num 22\n",
      "batch num 23\n",
      "batch num 24\n",
      "batch num 25\n",
      "batch num 26\n",
      "batch num 27\n",
      "batch num 28\n",
      "batch num 29\n",
      "batch num 30\n",
      "batch num 31\n",
      "batch num 32\n",
      "batch num 33\n",
      "batch num 34\n",
      "batch num 35\n",
      "batch num 36\n",
      "batch num 37\n",
      "batch num 38\n",
      "batch num 39\n",
      "batch num 40\n",
      "batch num 41\n",
      "batch num 42\n",
      "batch num 43\n",
      "batch num 44\n",
      "batch num 45\n",
      "batch num 46\n",
      "batch num 47\n",
      "batch num 48\n",
      "batch num 49\n",
      "batch num 50\n",
      "batch num 51\n",
      "batch num 52\n",
      "batch num 53\n",
      "batch num 54\n",
      "batch num 55\n",
      "batch num 56\n",
      "batch num 57\n",
      "batch num 58\n",
      "batch num 59\n",
      "batch num 60\n",
      "batch num 61\n",
      "batch num 62\n",
      "batch num 63\n",
      "batch num 64\n",
      "batch num 65\n",
      "batch num 66\n",
      "batch num 67\n",
      "batch num 68\n",
      "batch num 69\n",
      "batch num 70\n",
      "batch num 71\n",
      "batch num 72\n",
      "batch num 73\n",
      "batch num 74\n",
      "batch num 75\n",
      "batch num 76\n",
      "batch num 77\n",
      "batch num 78\n",
      "batch num 79\n",
      "batch num 80\n",
      "batch num 81\n",
      "batch num 82\n",
      "batch num 83\n",
      "batch num 84\n",
      "batch num 85\n",
      "batch num 86\n",
      "batch num 87\n",
      "batch num 88\n",
      "batch num 89\n",
      "batch num 90\n",
      "batch num 91\n",
      "batch num 92\n",
      "batch num 93\n",
      "batch num 94\n",
      "batch num 95\n",
      "batch num 96\n",
      "batch num 97\n",
      "batch num 98\n",
      "batch num 99\n",
      "batch num 100\n",
      "batch num 101\n",
      "batch num 102\n",
      "batch num 103\n",
      "batch num 104\n",
      "batch num 105\n",
      "batch num 106\n",
      "batch num 107\n",
      "batch num 108\n",
      "batch num 109\n",
      "batch num 110\n",
      "batch num 111\n",
      "batch num 112\n",
      "batch num 113\n",
      "batch num 114\n",
      "batch num 115\n",
      "batch num 116\n",
      "batch num 117\n",
      "batch num 118\n",
      "batch num 119\n",
      "batch num 120\n",
      "batch num 121\n",
      "batch num 122\n",
      "batch num 123\n",
      "batch num 124\n",
      "batch num 125\n",
      "batch num 126\n",
      "batch num 127\n",
      "batch num 128\n",
      "batch num 129\n",
      "batch num 130\n",
      "batch num 131\n",
      "batch num 132\n",
      "batch num 133\n",
      "batch num 134\n",
      "batch num 135\n",
      "batch num 136\n",
      "batch num 137\n",
      "batch num 138\n",
      "batch num 139\n",
      "batch num 140\n",
      "batch num 141\n",
      "batch num 142\n",
      "batch num 143\n",
      "batch num 144\n",
      "batch num 145\n",
      "batch num 146\n",
      "batch num 147\n",
      "batch num 148\n",
      "batch num 149\n",
      "batch num 150\n",
      "batch num 151\n",
      "batch num 152\n",
      "batch num 153\n",
      "batch num 154\n",
      "batch num 155\n",
      "batch num 156\n",
      "batch num 157\n",
      "batch num 158\n",
      "batch num 159\n",
      "batch num 160\n",
      "batch num 161\n",
      "batch num 162\n",
      "batch num 163\n",
      "batch num 164\n",
      "batch num 165\n",
      "batch num 166\n",
      "batch num 167\n",
      "batch num 168\n",
      "batch num 169\n",
      "batch num 170\n",
      "batch num 171\n",
      "batch num 172\n",
      "batch num 173\n",
      "batch num 174\n",
      "batch num 175\n",
      "batch num 176\n",
      "batch num 177\n",
      "batch num 178\n",
      "batch num 179\n",
      "batch num 180\n",
      "batch num 181\n",
      "batch num 182\n",
      "batch num 183\n",
      "batch num 184\n",
      "batch num 185\n",
      "batch num 186\n",
      "batch num 187\n",
      "batch num 188\n",
      "batch num 189\n",
      "batch num 190\n",
      "batch num 191\n",
      "batch num 192\n",
      "batch num 193\n",
      "batch num 194\n",
      "batch num 195\n",
      "batch num 196\n",
      "batch num 197\n",
      "batch num 198\n",
      "batch num 199\n",
      "batch num 200\n",
      "batch num 201\n",
      "batch num 202\n",
      "batch num 203\n",
      "batch num 204\n",
      "batch num 205\n",
      "batch num 206\n",
      "batch num 207\n",
      "batch num 208\n",
      "batch num 209\n",
      "batch num 210\n",
      "batch num 211\n",
      "batch num 212\n",
      "batch num 213\n",
      "batch num 214\n",
      "batch num 215\n",
      "batch num 216\n",
      "batch num 217\n",
      "batch num 218\n",
      "batch num 219\n",
      "batch num 220\n",
      "batch num 221\n",
      "batch num 222\n",
      "batch num 223\n",
      "batch num 224\n",
      "batch num 225\n",
      "batch num 226\n",
      "batch num 227\n",
      "batch num 228\n",
      "batch num 229\n",
      "batch num 230\n",
      "batch num 231\n",
      "batch num 232\n",
      "batch num 233\n",
      "batch num 234\n",
      "batch num 235\n",
      "batch num 236\n",
      "batch num 237\n",
      "batch num 238\n",
      "batch num 239\n",
      "batch num 240\n",
      "batch num 241\n",
      "batch num 242\n",
      "batch num 243\n",
      "batch num 244\n",
      "batch num 245\n",
      "batch num 246\n",
      "batch num 247\n",
      "batch num 248\n",
      "batch num 249\n",
      "batch num 250\n",
      "batch num 251\n",
      "batch num 252\n",
      "batch num 253\n",
      "batch num 254\n",
      "batch num 255\n",
      "batch num 256\n",
      "batch num 257\n",
      "batch num 258\n",
      "batch num 259\n",
      "batch num 260\n",
      "batch num 261\n",
      "batch num 262\n",
      "batch num 263\n",
      "batch num 264\n",
      "batch num 265\n",
      "batch num 266\n",
      "batch num 267\n",
      "batch num 268\n",
      "batch num 269\n",
      "batch num 270\n",
      "batch num 271\n",
      "batch num 272\n",
      "batch num 273\n",
      "batch num 274\n",
      "batch num 275\n",
      "batch num 276\n",
      "batch num 277\n",
      "batch num 278\n",
      "batch num 279\n",
      "batch num 280\n",
      "batch num 281\n",
      "batch num 282\n",
      "batch num 283\n",
      "batch num 284\n",
      "batch num 285\n",
      "batch num 286\n",
      "batch num 287\n",
      "batch num 288\n",
      "batch num 289\n",
      "batch num 290\n",
      "batch num 291\n",
      "batch num 292\n",
      "batch num 293\n",
      "batch num 294\n",
      "batch num 295\n",
      "batch num 296\n",
      "batch num 297\n",
      "batch num 298\n",
      "batch num 299\n",
      "batch num 300\n",
      "batch num 301\n",
      "batch num 302\n",
      "batch num 303\n",
      "batch num 304\n",
      "batch num 305\n",
      "batch num 306\n",
      "batch num 307\n",
      "batch num 308\n",
      "batch num 309\n",
      "batch num 310\n",
      "batch num 311\n",
      "batch num 312\n",
      "batch num 313\n",
      "batch num 314\n",
      "batch num 315\n",
      "batch num 316\n",
      "batch num 317\n",
      "batch num 318\n",
      "batch num 319\n",
      "batch num 320\n",
      "batch num 321\n",
      "batch num 322\n",
      "batch num 323\n",
      "batch num 324\n",
      "batch num 325\n",
      "batch num 326\n",
      "batch num 327\n",
      "batch num 328\n",
      "batch num 329\n",
      "batch num 330\n",
      "batch num 331\n",
      "batch num 332\n",
      "batch num 333\n",
      "batch num 334\n",
      "batch num 335\n",
      "batch num 336\n",
      "batch num 337\n",
      "batch num 338\n",
      "batch num 339\n",
      "batch num 340\n",
      "batch num 341\n",
      "batch num 342\n",
      "batch num 343\n",
      "batch num 344\n",
      "batch num 345\n",
      "batch num 346\n",
      "batch num 347\n",
      "batch num 348\n",
      "batch num 349\n",
      "batch num 350\n",
      "batch num 351\n",
      "batch num 352\n",
      "batch num 353\n",
      "batch num 354\n",
      "batch num 355\n",
      "batch num 356\n",
      "batch num 357\n",
      "batch num 358\n",
      "batch num 359\n",
      "batch num 360\n",
      "batch num 361\n",
      "batch num 362\n",
      "batch num 363\n",
      "batch num 364\n",
      "batch num 365\n",
      "batch num 366\n",
      "batch num 367\n",
      "batch num 368\n",
      "batch num 369\n",
      "batch num 370\n",
      "batch num 371\n",
      "batch num 372\n",
      "batch num 373\n",
      "batch num 374\n",
      "batch num 375\n",
      "batch num 376\n",
      "batch num 377\n",
      "batch num 378\n",
      "batch num 379\n",
      "batch num 380\n",
      "batch num 381\n",
      "batch num 382\n",
      "batch num 383\n",
      "batch num 384\n",
      "batch num 385\n",
      "batch num 386\n",
      "batch num 387\n",
      "batch num 388\n",
      "batch num 389\n",
      "batch num 390\n",
      "batch num 391\n",
      "batch num 392\n",
      "batch num 393\n",
      "batch num 394\n",
      "batch num 395\n",
      "batch num 396\n",
      "batch num 397\n",
      "batch num 398\n",
      "batch num 399\n",
      "batch num 400\n",
      "batch num 401\n",
      "batch num 402\n",
      "batch num 403\n",
      "batch num 404\n",
      "batch num 405\n",
      "batch num 406\n",
      "batch num 407\n",
      "batch num 408\n",
      "batch num 409\n",
      "batch num 410\n",
      "batch num 411\n",
      "batch num 412\n",
      "batch num 413\n",
      "batch num 414\n",
      "batch num 415\n",
      "batch num 416\n",
      "batch num 417\n",
      "batch num 418\n",
      "batch num 419\n",
      "batch num 420\n",
      "batch num 421\n",
      "batch num 422\n",
      "batch num 423\n",
      "batch num 424\n",
      "batch num 425\n",
      "batch num 426\n",
      "batch num 427\n",
      "batch num 428\n",
      "batch num 429\n",
      "batch num 430\n",
      "batch num 431\n",
      "batch num 432\n",
      "batch num 433\n",
      "batch num 434\n",
      "batch num 435\n",
      "batch num 436\n",
      "batch num 437\n",
      "batch num 438\n",
      "batch num 439\n",
      "batch num 440\n",
      "batch num 441\n",
      "batch num 442\n",
      "batch num 443\n",
      "batch num 444\n",
      "batch num 445\n",
      "batch num 446\n",
      "batch num 447\n",
      "batch num 448\n",
      "batch num 449\n",
      "batch num 450\n",
      "batch num 451\n",
      "batch num 452\n",
      "batch num 453\n",
      "batch num 454\n",
      "batch num 455\n",
      "batch num 456\n",
      "batch num 457\n",
      "batch num 458\n",
      "batch num 459\n",
      "batch num 460\n",
      "batch num 461\n",
      "batch num 462\n",
      "batch num 463\n",
      "batch num 464\n",
      "batch num 465\n",
      "batch num 466\n",
      "batch num 467\n",
      "batch num 468\n",
      "batch num 469\n",
      "batch num 470\n",
      "batch num 471\n",
      "batch num 472\n",
      "batch num 473\n",
      "batch num 474\n",
      "batch num 475\n",
      "batch num 476\n",
      "batch num 477\n",
      "batch num 478\n",
      "batch num 479\n",
      "batch num 480\n",
      "batch num 481\n",
      "batch num 482\n",
      "batch num 483\n",
      "batch num 484\n",
      "batch num 485\n",
      "batch num 486\n",
      "batch num 487\n",
      "batch num 488\n",
      "batch num 489\n",
      "batch num 490\n",
      "batch num 491\n",
      "batch num 492\n",
      "batch num 493\n",
      "batch num 494\n",
      "batch num 495\n",
      "batch num 496\n",
      "batch num 497\n",
      "batch num 498\n",
      "batch num 499\n",
      "batch num 500\n",
      "batch num 501\n",
      "batch num 502\n",
      "batch num 503\n",
      "batch num 504\n",
      "batch num 505\n",
      "batch num 506\n",
      "batch num 507\n",
      "batch num 508\n",
      "batch num 509\n",
      "batch num 510\n",
      "batch num 511\n",
      "batch num 512\n",
      "batch num 513\n",
      "batch num 514\n",
      "batch num 515\n",
      "batch num 516\n",
      "batch num 517\n",
      "batch num 518\n",
      "batch num 519\n",
      "batch num 520\n",
      "batch num 521\n",
      "batch num 522\n",
      "batch num 523\n",
      "batch num 524\n",
      "batch num 525\n",
      "batch num 526\n",
      "batch num 527\n",
      "batch num 528\n",
      "batch num 529\n",
      "batch num 530\n",
      "batch num 531\n",
      "batch num 532\n",
      "batch num 533\n",
      "batch num 534\n",
      "batch num 535\n",
      "batch num 536\n",
      "batch num 537\n",
      "batch num 538\n",
      "batch num 539\n",
      "batch num 540\n",
      "batch num 541\n",
      "batch num 542\n",
      "batch num 543\n",
      "batch num 544\n",
      "batch num 545\n",
      "batch num 546\n",
      "batch num 547\n",
      "batch num 548\n",
      "batch num 549\n",
      "batch num 550\n",
      "batch num 551\n",
      "batch num 552\n",
      "batch num 553\n",
      "batch num 554\n",
      "batch num 555\n",
      "batch num 556\n",
      "batch num 557\n",
      "batch num 558\n",
      "batch num 559\n",
      "batch num 560\n",
      "batch num 561\n",
      "batch num 562\n",
      "batch num 563\n",
      "batch num 564\n",
      "batch num 565\n",
      "batch num 566\n",
      "batch num 567\n",
      "batch num 568\n",
      "batch num 569\n",
      "batch num 570\n",
      "batch num 571\n",
      "batch num 572\n",
      "batch num 573\n",
      "batch num 574\n",
      "batch num 575\n",
      "batch num 576\n",
      "batch num 577\n",
      "batch num 578\n",
      "batch num 579\n",
      "batch num 580\n",
      "batch num 581\n",
      "batch num 582\n",
      "batch num 583\n",
      "batch num 584\n",
      "batch num 585\n",
      "batch num 586\n",
      "batch num 587\n",
      "batch num 588\n",
      "batch num 589\n",
      "batch num 590\n",
      "batch num 591\n",
      "batch num 592\n",
      "batch num 593\n",
      "batch num 594\n",
      "batch num 595\n",
      "batch num 596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch num 597\n",
      "batch num 598\n",
      "batch num 599\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done\n",
      "forwarding\n",
      "forwarding\n",
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "train_network_batch(100, 600)\n",
    "print('training done')\n",
    "layers[0].set_y(train_images[0].flatten())\n",
    "for i in range(1, len(layers)):\n",
    "  print('forwarding')\n",
    "  # print(layers[i].y_vec)\n",
    "  layers[i].forward(layers[i-1].y_vec)\n",
    "  # print(layers[i].y_vec)\n",
    "print(softmax(layers[-1].y_vec))\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forwarding\n",
      "forwarding\n",
      "forwarding\n",
      "[0.10267665 0.10386278 0.09653331 0.10075091 0.10079535 0.0959269\n",
      " 0.10076079 0.09985069 0.09804901 0.10079361]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "layers[0].set_y(train_images[2].flatten())\n",
    "for i in range(1, len(layers)):\n",
    "  print('forwarding')\n",
    "  # print(layers[i].y_vec)\n",
    "  layers[i].forward(layers[i-1].y_vec)\n",
    "  # print(layers[i].y_vec)\n",
    "print(softmax(layers[-1].y_vec))\n",
    "print(train_labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 % 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
